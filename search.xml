<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title></title>
      <url>/2017/06/17/decision_tree/</url>
      <content type="html"><![CDATA[<p>此笔记根据《machine learning in action》和周志华教授的《机器学习》所作。</p>
<h2 id="决策树的原理"><a href="#决策树的原理" class="headerlink" title="决策树的原理"></a>决策树的原理</h2><h3 id="决策树的构造"><a href="#决策树的构造" class="headerlink" title="决策树的构造"></a><strong>决策树的构造</strong></h3><ul>
<li><strong>优点：</strong>计算复杂度不高，输出结果易于理解，对中间值的确实不敏感，可以处理不相关特征数据。</li>
<li><strong>缺点：</strong>可能会产生过度匹配问题。</li>
<li><strong>适用数据类型：</strong>数值型和标称型</li>
</ul>
<a id="more"></a>
<p>《machine learning  in action》:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">If so return 类标签；</div><div class="line">Else</div><div class="line">    寻找划分数据集的最好特征</div><div class="line">    划分数据集</div><div class="line">    创建分支节点</div><div class="line">       for每个划分的子集</div><div class="line">          调用函数createBranch并增加返回结果到分支节点中</div><div class="line">    return 分支节点</div></pre></td></tr></table></figure></p>
<p>上面的伪代码createBranch是一个递归函数，在倒数第二行调用了它自己。<br>《机器学习》：<br><img src="http://img.blog.csdn.net/20170602222239103?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>###<strong>决策树的一般流程</strong></p>
<ol>
<li><strong>收集数据：</strong>可以使用任何方法。</li>
<li><strong>准备数据：</strong>树构造算法只适用于<strong>标称型数据</strong>（标称型目标变量的结果只在有限目标集中取值，如真与假[标称型目标变量主要用于分类]）,因此数值型数据必须离散化。</li>
<li><strong>分析数据：</strong>可以使用任何方法，构造书完成之后，我们应该检查图形是否符合预期。</li>
<li><strong>训练算法：</strong>构造树的数据结构。</li>
<li><strong>测试算法：</strong>使用经验树计算错误率。</li>
</ol>
<p><strong>决策树的变量可以有两种：</strong></p>
<ol>
<li><p>数字型（Numeric）：变量类型是整数或浮点数，如“年收入”。用“&gt;=”，“&gt;”,“&lt;”或“&lt;=”作为分割条件（排序后，利用已有的分割情况，可以优化分割算法的时间复杂度）。</p>
</li>
<li><p>名称型（Nominal）：类似编程语言中的枚举类型，变量只能重有限的选项中选取，比如“婚姻情况”，只能是“单身”，“已婚”或“离婚”。使用“=”来分割。</p>
</li>
</ol>
<p><strong>一些决策树算法采用二分法划分数据，本文并不采用这种方法，而采用<em>ID3算法</em>。</strong></p>
<h3 id="熵的推导"><a href="#熵的推导" class="headerlink" title="熵的推导"></a><strong>熵的推导</strong></h3><p>参考PRML：<br>熵的含义：<br>考虑一个集合，包含N个完全相同的物体，这些物体要被分到m个箱子里，使得第i个箱子中有$n_i$ 个物体。考虑把物体分配到箱子中的不同方案的数量，有N种方式选择第一个物体，有（N-1）种方式选择第二个物体，以此类推。因此总共有N！种方式把N个物体分配到箱子中（也可以如此考虑：将N个物体先进行全排列，然后选前$n_1$个放入第1个箱子，选前$n_2 $个放入第2个箱子，依次类推，则放入箱子的方案有N！种）。然而，我们并不想区分每个箱子内部物体的排列。所以上述的方案数量需要除以每个箱子内部排列的数量，即在第i个箱子中，有$n_i！$种方案对物体进行全排列，因此，把N个箱子分配到箱子中的总方案数量为：</p>
<p><center><br><img src="http://img.blog.csdn.net/20170602233318436?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="30%" height="30%"><br></center><br>这被称为乘数。<br>熵被定义为通过适当的参数放缩后的对数乘数，即</p>
<p><center><br><img src="http://img.blog.csdn.net/20170602234657912?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="20%" height="20%"><br></center><br>在下面的推导中，将会用到Stirling公式的估计：<br><img src="http://img.blog.csdn.net/20170603110124302?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20170603110027505?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><strong>熵的推导：</strong><br><img src="http://img.blog.csdn.net/20170603112104061?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>决策树算法中比较有代表性的是ID3[Quinlan,1979,1986]，C4.5[Quinlan,1993]和CART[Breiman et al.,1984]</p>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a><strong>ID3算法</strong></h3><p>维基百科解释：<a href="https://en.wikipedia.org/wiki/ID3_algorithm" target="_blank" rel="external">https://en.wikipedia.org/wiki/ID3_algorithm</a><br>ID3是以“信息增益”为准则来选择划分属性的。<br><img src="http://img.blog.csdn.net/20170604211002327?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a><strong>C4.5算法</strong></h3><p>C4.5算法主要以“信息率”来选择最优划分属性。<br><img src="http://img.blog.csdn.net/20170604211626464?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20170604211640230?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h3 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a><strong>CART算法</strong></h3><p>CART决策树是以“基尼指数”为准则来选择划分属性。此算法不仅可用于分类还可以用于回归。<br><img src="http://img.blog.csdn.net/20170604212130490?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h2 id="决策树的构建"><a href="#决策树的构建" class="headerlink" title="决策树的构建"></a>决策树的构建</h2><p><strong>《 machine learning in action》之决策树</strong></p>
<h3 id="计算给定数据集的香农熵"><a href="#计算给定数据集的香农熵" class="headerlink" title="计算给定数据集的香农熵"></a><strong>计算给定数据集的香农熵</strong></h3><p>创建文件trees.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># -*- coding=utf-8 -*-</div><div class="line">#计算给定数据集的熵</div><div class="line">from math import log</div><div class="line"></div><div class="line">def calcShannonEnt(dataSet):</div><div class="line">    numEntries = len(dataSet)</div><div class="line">    labelCounts = &#123;&#125;  #实例总数</div><div class="line">    for featVec in dataSet:</div><div class="line">        #为所有可能分类创建字典</div><div class="line">        currentLabel = featVec[-1]       #将最后一列，即分类结果存入currentLabel</div><div class="line">        if currentLabel not in labelCounts.keys():       #若分类结果已经在labelCounts这个字典中</div><div class="line">            labelCounts[currentLabel] = 0              #若当前label不存在,则扩展字典,加入此键值</div><div class="line">        labelCounts[currentLabel] += 1                 #字典中的每个键值都记录了当前类别的数量</div><div class="line">    #print &apos;labelCounts,currentLabel:&apos;,labelCounts,currentLabel</div><div class="line">    #print &apos;labelCounts.keys()&apos;,labelCounts.keys()</div><div class="line">    #print &apos;labelCounts.values()&apos;,labelCounts.values()</div><div class="line">    shannonEnt = 0.0</div><div class="line">    for key in labelCounts:</div><div class="line">        prob = float(labelCounts[key])/numEntries</div><div class="line">        shannonEnt -= prob*log(prob,2)  #求以2为底的对数，其和即为熵</div><div class="line">        #print &apos;labelCounts[key]&apos;,labelCounts[key]</div><div class="line">    return shannonEnt</div></pre></td></tr></table></figure></p>
<h3 id="创建或导入dataSet"><a href="#创建或导入dataSet" class="headerlink" title="创建或导入dataSet"></a><strong>创建或导入dataSet</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#鱼类数据集</div><div class="line">def createDataSet():</div><div class="line">    dataSet = [[1,1,&apos;yes&apos;],</div><div class="line">               [1,1,&apos;yes&apos;],</div><div class="line">               [1,0,&apos;no&apos;],</div><div class="line">               [0,1,&apos;no&apos;],</div><div class="line">               [0,1,&apos;no&apos;]]</div><div class="line">    labels = [&apos;no surfacing&apos;,&apos;flippers&apos;]</div><div class="line">    return dataSet,labels</div></pre></td></tr></table></figure>
<p><strong>在命令提示符下输入：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">In[9]: import trees</div><div class="line">In[10]: myDat,labels = trees.createDataSet()</div><div class="line">In[11]: myDat</div><div class="line">Out[11]: </div><div class="line">[[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]]</div><div class="line">In[12]: labels</div><div class="line">Out[12]: </div><div class="line">[&apos;no surfacing&apos;, &apos;flippers&apos;]</div><div class="line">In[13]: trees.calcShannonEnt(myDat)</div><div class="line">#混合的数据越多，熵越高，测试：</div><div class="line">In[18]: myDat[0][-1] = &apos;maybe&apos;</div><div class="line">In[19]: myDat</div><div class="line">Out[19]: </div><div class="line">[[1, 1, &apos;maybe&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]]</div><div class="line">In[20]: trees.calcShannonEnt(myDat)</div><div class="line">Out[20]: </div><div class="line">1.3709505944546687</div></pre></td></tr></table></figure></p>
<h3 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a><strong>划分数据集</strong></h3><p>取出符合要求某个特征属性值的样本，并将其此特征从数据集中去除。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#按照给定特征划分数据集</div><div class="line">def splitDataSet(dataSet,axis,value):  #待划分的数据集,划分数据集的特征(第几列),需要返回的特征的值，（axis--&gt;a,value--&gt;v）</div><div class="line">    #为了不修改原始数据集,创建新的list对象</div><div class="line">    retDataSet = []</div><div class="line">    for featVec in dataSet:</div><div class="line">        #将符合特征的数据抽取出来</div><div class="line">        if featVec[axis] == value:  #Python中的数据.即featVec中的数据从第0列开始,[0,1,2,3,4,5,……]</div><div class="line">            reducedFeatVec = featVec[:axis] #[:axis]表示前axis行,若axis为3,则表示取festVec的前3列,即第[0,1,2]列</div><div class="line">            reducedFeatVec.extend(featVec[axis+1:])    #[axis+1:] 表示跳过axis+1列,从下一列数据取到最后一列的数据,即跳过第[3]列,从第[4]列到最后一列</div><div class="line">            retDataSet.append(reducedFeatVec)</div><div class="line">    return retDataSet</div></pre></td></tr></table></figure></p>
<p><strong>在Python命令行中输入：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">In[16]: reload(trees)</div><div class="line">Out[16]: </div><div class="line">&lt;module &apos;trees&apos; from &apos;/home/vickyleexy/PycharmProjects/Classification of contact lenses/trees.py&apos;&gt;</div><div class="line">In[17]: myDat,labels = trees.createDataSet()</div><div class="line">In[18]: myDat</div><div class="line">Out[18]: </div><div class="line">[[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]]</div><div class="line">In[19]: trees.splitDataSet(myDat,0,1) #抽取出数据集中第0列中数据值为1的样本，并将此列剔除，组成新的样本集</div><div class="line">Out[19]: </div><div class="line">[[1, &apos;yes&apos;], [1, &apos;yes&apos;], [0, &apos;no&apos;]]</div><div class="line">In[20]: trees.splitDataSet(myDat,0,0) #抽取出数据集中第0列中数据值为0的样本，并将此列剔除，组成新的样本集</div><div class="line">Out[20]: </div><div class="line">[[1, &apos;no&apos;], [1, &apos;no&apos;]]</div><div class="line">In[21]: trees.splitDataSet(myDat,1,0) #抽取出数据集中第1列中数据值为0的样本，并将此列剔除，组成新的样本集</div><div class="line">Out[21]: </div><div class="line">[[1, &apos;no&apos;]]</div></pre></td></tr></table></figure></p>
<h3 id="选取最好的数据集划分方式"><a href="#选取最好的数据集划分方式" class="headerlink" title="选取最好的数据集划分方式"></a><strong>选取最好的数据集划分方式</strong></h3><p>即选取取出信息增益最大的特征。<strong>信息增益</strong>是熵减少或者说信息无序度的减少，信息增益越大，信息无序度减少越大，信息的可确定性越强。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">#选择最好的数据集划分数据,即计算每种特征信息熵 Gain(D,a)</div><div class="line">def chooseBestFeatureToSplit(dataSet):</div><div class="line">    numFeatures = len(dataSet[0]) - 1                     #可选特征的个数</div><div class="line">    baseEntropy = calcShannonEnt(dataSet)  # 计算总体信息熵Ent(D)</div><div class="line">    bestInfoGain = 0.0;       #初始化最好的信息增益</div><div class="line">    bestFeature = -1;        #初始化选取的最好的特征</div><div class="line">    #创建唯一的分类标签列表</div><div class="line">    for i in range(numFeatures):           #遍历各个特征</div><div class="line">        featList = [example[i] for example in dataSet]   #将第i列特征的值选取出来,并存入featList</div><div class="line">        uniqueVals = set(featList)         #将featList存为集合的格式,即去除featList中重复的元素,因此uniqueVals中为每个特征的中不同的属性</div><div class="line">        newEntropy = 0.0</div><div class="line">        #计算每种划分方式的信息熵</div><div class="line">        for value in uniqueVals:        #遍历每个特征中的各个属性</div><div class="line">            subDataSet = splitDataSet(dataSet,i,value)       #选取符合条件的特征,并将此特征从样本中去除，以便进行下面的进一步计算</div><div class="line">            prob = len(subDataSet)/float(len(dataSet))       #符合此特征中此属性的个数占总体样本的比例,即|D^v|/|D|</div><div class="line">            newEntropy += prob * calcShannonEnt(subDataSet)  #计算各个特征中每个属性的加权信息熵的和</div><div class="line">        infoGain = baseEntropy - newEntropy               #计算信息增益,即Gain(D,a)</div><div class="line">        #计算最好额信息增益</div><div class="line">        if (infoGain &gt; bestInfoGain):</div><div class="line">            bestInfoGain = infoGain</div><div class="line">            bestFeature = i</div><div class="line">    print &apos;最好的特征,最好的信息增益：&apos;,bestFeature,bestInfoGain</div><div class="line">    return bestFeature</div></pre></td></tr></table></figure></p>
<p><strong>在Python命令行下输入以下代码进行测试：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">In[9]: reload(trees)</div><div class="line">Out[9]: </div><div class="line">&lt;module &apos;trees&apos; from &apos;/home/vickyleexy/PycharmProjects/Classification of contact lenses/trees.py&apos;&gt;</div><div class="line">In[10]: myDat,labels = trees.createDataSet()</div><div class="line">In[11]: myDat</div><div class="line">Out[11]: </div><div class="line">[[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]]</div><div class="line">In[12]: trees.chooseBestFeatureToSplit(myDat)</div><div class="line">最好的特征,最好的信息增益： 0 , 0.419973094022</div><div class="line">Out[12]: </div><div class="line">0</div></pre></td></tr></table></figure></p>
<h3 id="递归构建决策树"><a href="#递归构建决策树" class="headerlink" title="递归构建决策树"></a><strong>递归构建决策树</strong></h3><p>递归结束的条件：</p>
<ul>
<li>程序遍历完所有划分数据集的属性</li>
<li>每个分支下的所有实例都具有相同的分类</li>
</ul>
<p>若已经处理了所有的属性,但类标签依然不是唯一的,此时采用多数表决的方法决定叶子节点的分类。<br>在trees.py文件的顶部添加operator库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">import operator</div></pre></td></tr></table></figure></p>
<p>统计剩余样本中属于哪一类别最多的数量最多：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">def majorityCnt(classList):     #classList类别列表</div><div class="line">    classCount = &#123;&#125;             #新建立一个字典</div><div class="line">    for vote in classList:       #遍历所有的类别</div><div class="line">        #统计各类别剩余样本的数量</div><div class="line">        if vote not in classCount.keys():     #如果此类别不在classCount的key中</div><div class="line">            classCount[vote] = 0</div><div class="line">            classCount[vote] += 1</div><div class="line">    sortedClassCount = sorted(classCount.iteritems(),key = operator.itemgetter(1),reverse = True) #将统计好的剩余样本类别和其数量，根据其数量进行从大到小的排序</div><div class="line">    return sortedClassCount[0][0]     #取出剩余样本中数量最大的类别名称</div></pre></td></tr></table></figure></p>
<p><strong>创建树的函数代码：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">#创建树的函数代码</div><div class="line">def createTree(dataSet,labels):</div><div class="line">    classList = [example[-1] for example in dataSet]</div><div class="line">    #类别完全相同则停止继续划分</div><div class="line">    if classList.count(classList[0]) == len(classList):  #若classList中第一个类别的数量等于样本的总数量,即样本类别完全相同</div><div class="line">        return classList[0]</div><div class="line">    #遍历完所有特征时返回出现次数最多的</div><div class="line">    if len(dataSet[0]) == 1:</div><div class="line">        return majorityCnt(classList)</div><div class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</div><div class="line">    bestFeatLabel = labels[bestFeat]</div><div class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125;</div><div class="line">    del(labels[bestFeat]) #去掉已经使用的（bestFeat）类标签</div><div class="line">    #得到最好的特征这一列,包含其所有属性值的列表</div><div class="line">    featValues = [example[bestFeat] for example in dataSet]</div><div class="line">    uniqueVals = set(featValues)        #去掉featValues列表中重复的属性</div><div class="line">    for value in uniqueVals:             #遍历最好的特征中所有的属性</div><div class="line">        subLabels = labels[:]            #复制del(labels[bestFeat])后的结果,并将其存在新列表变量subLabels中</div><div class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)</div><div class="line">    return myTree</div></pre></td></tr></table></figure></p>
<p>命令行中输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">In[66]: reload(trees)</div><div class="line">Out[66]: </div><div class="line">&lt;module &apos;trees&apos; from &apos;/home/vickyleexy/PycharmProjects/Classification of contact lenses/trees.py&apos;&gt;</div><div class="line">In[67]: myDat,labels = trees.createDataSet()</div><div class="line">In[68]: myTree = trees.createTree(myDat,labels)</div><div class="line">最好的特征,最好的信息增益： 0 , 0.419973094022</div><div class="line">最好的特征,最好的信息增益： 0 , 0.918295834054</div><div class="line">In[69]: myTree</div><div class="line">Out[69]: </div><div class="line">&#123;&apos;no surfacing&apos;: &#123;0: &apos;no&apos;, 1: &#123;&apos;flippers&apos;: &#123;0: &apos;no&apos;, 1: &apos;yes&apos;&#125;&#125;&#125;&#125;</div></pre></td></tr></table></figure></p>
<h2 id="使用matplotlib绘制树形图并测试算法"><a href="#使用matplotlib绘制树形图并测试算法" class="headerlink" title="使用matplotlib绘制树形图并测试算法"></a>使用matplotlib绘制树形图并测试算法</h2><p>在<a href="http://blog.csdn.net/u012150360/article/details/72868619" target="_blank" rel="external"><strong>决策树02——决策树的构建</strong></a>中，我们将已经进行分类的数据存储在字典中，然而字典的表示形式非常不直观，也不容易理解，所以我们将字典中的信息绘制成树形图。</p>
<h3 id="Matplotlib注解功能"><a href="#Matplotlib注解功能" class="headerlink" title="Matplotlib注解功能"></a><strong>Matplotlib注解功能</strong></h3><p>　　Matplotlib提供一个注解工具annotations，它可以在数据图形上添加文本注释。</p>
<p>　　以下将使用Matplotlib的注解功能绘制树形图，它可以对文字着色，并提供多种形状以供选择，而且我们还可以反转箭头，将它指向文本框而不是数据点。</p>
<p>　　新建名为treeplotter.py的新文件，将输入下面的程序代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"># -*-coding=utf-8 -*-</div><div class="line"></div><div class="line">#使用文本朱姐绘制树节点</div><div class="line">import matplotlib.pyplot as plt</div><div class="line"></div><div class="line">#定义文本框和箭头格式</div><div class="line">#定义决策树决策结果的属性（决策节点or叶节点）,用字典来定义</div><div class="line">#下面的字典定义也可以写作 decisionNode = &#123;boxstyle：’sawtooth‘,fc=’0.8‘&#125;</div><div class="line">decisionNode = dict(boxstyle = &quot;sawtooth&quot;, fc = &quot;0.8&quot;)       #决策节点,boxstyle为文本框类型,sawtooth是锯齿形,fc是边框内填充的颜色</div><div class="line">leafNode = dict(boxstyle = &quot;round&quot;,fc=&quot;0.8&quot;)                #叶节点,定义决策树的叶子结点的描述属性</div><div class="line">arrow_args = dict(arrowstyle = &quot;&lt;-&quot;)                         #箭头格式</div><div class="line"></div><div class="line">#绘制带箭头的注释</div><div class="line">def plotNode(nodeTxt,centerPt,parentPt,nodeType):           #nodeTxt是显示的文本,centerPt是文本的中心点,parentPt是箭头的起点坐标,nodeType是一个字典 注解的形状</div><div class="line">    createPlot.ax1.annotate(nodeTxt,xy = parentPt, xycoords = &apos;axes fraction&apos;,  #xy为箭头的起始坐标,0,0 is lower left of axes and 1,1 is upper right</div><div class="line">                            xytext = centerPt,textcoords = &apos;axes fraction&apos;, #xytext为注解内容的坐标</div><div class="line">                            va = &quot;center&quot;,ha = &quot;center&quot;,bbox = nodeType,arrowprops = arrow_args) #bbox注解文本框的形状,arrowprops是指箭头的形状</div><div class="line"></div><div class="line">def createPlot():</div><div class="line">    fig = plt.figure(1,facecolor=&apos;white&apos;)  #类似于matlab的figure,定义一个画布,其背景为白色</div><div class="line">    fig.clf()                 #把画布清空</div><div class="line">    createPlot.ax1 = plt.subplot(111,frameon=False) # createPlot.ax1为全局变量,绘制图像的句柄,subplot为定义了一个绘图,111表示figure中的图有1行1列,即1个,最后的1代表第一个图,</div><div class="line">    plotNode(U&apos;决策节点&apos;,(0.5,0.1),(0.1,0.5), decisionNode)</div><div class="line">    plotNode(U&apos;叶节点&apos;,(0.8,0.1),(0.3,0.8), leafNode)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure></p>
<p><strong>注意：以上程序运行时会出现中文变成小方框的现象，将以下几行代码添加到文件的开始处。</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from pylab import *</div><div class="line">mpl.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;]  #指定默认字体</div><div class="line">mpl.rcParams[&apos;axes.unicode_minus&apos;] = False</div></pre></td></tr></table></figure></p>
<p><strong>在命令行输入：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">In[70]: import treePlotter</div><div class="line">Backend TkAgg is interactive backend. Turning interactive mode on.</div><div class="line">In[71]: treePlotter.createPlot()</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20170614231531328?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h3 id="构造注解树"><a href="#构造注解树" class="headerlink" title="构造注解树"></a>构造注解树</h3><p>　　我们虽然有x, y坐标，但是如何放置所有的树节点却是个问题。我们必须知道有多少个叶节点，以便可以正确确定x轴的长度，我们还需要知道树有多少层，以便可以正确的确定y轴的高度。<br>　　这里我们定义两个新函数getNumLeafs()和getTreeDepth()，来获取叶节点的输煤和树的层数。将下面的两个函数添加到treePlotter.py文件中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">#获取叶节点的数目和树的层次</div><div class="line">def getNumLeafs(myTree):</div><div class="line">    numLeaf = 0</div><div class="line">    firstStr = myTree.keys()[0]</div><div class="line">    secondDict = myTree[firstStr]</div><div class="line">    for key in secondDict.keys():</div><div class="line">        if type(secondDict[key]).__name__ ==&apos;dict&apos;:         #测试节点的数据类型是否为字典 ,type(secondDict[key]) ==dict 也是可以的</div><div class="line">            numLeaf += getNumLeafs(secondDict[key])</div><div class="line">        else: numLeaf += 1</div><div class="line">    return numLeaf</div><div class="line"></div><div class="line">def getTreeDepth(myTree):</div><div class="line">    maxDepth = 0</div><div class="line">    firstStr = myTree.keys()[0]</div><div class="line">    secondDict = myTree[firstStr]</div><div class="line">    for key in secondDict.keys():</div><div class="line">        if type(secondDict[key]).__name__ == &apos;dict&apos;:</div><div class="line">            thisDepth = 1 + getTreeDepth(secondDict[key])</div><div class="line">        else: thisDepth = 1</div><div class="line">        if thisDepth &gt; maxDepth :maxDepth = thisDepth</div><div class="line">    return maxDepth</div></pre></td></tr></table></figure></p>
<p>函数retrieveTree()输出预先存储的树信息，将 下面代码添加到文件treePlotter.py中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def retrieveTree(i):</div><div class="line">    listOfTrees = [&#123;&apos;no surfacing&apos;:&#123;0:&apos;0&apos;,1:&#123;&apos;flippers&apos;:&#123;0:&apos;no&apos;,1:&apos;yes&apos;&#125;&#125;&#125;&#125;,</div><div class="line">                   &#123;&apos;no surfacing&apos;: &#123;0: &apos;0&apos;, 1: &#123;&apos;flippers&apos;: &#123;0: &#123;&apos;head&apos;:&#123;0:&apos;no&apos;,1:&apos;yes&apos;&#125;&#125;, 1: &apos;no&apos;&#125;&#125;&#125;&#125;</div><div class="line">                   ]</div><div class="line">    return listOfTrees[i]</div></pre></td></tr></table></figure></p>
<p><strong>在命令行中输入：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">In[2]: import treePlotter</div><div class="line">Backend TkAgg is interactive backend. Turning interactive mode on.</div><div class="line">In[3]: treePlotter.retrieveTree(0)</div><div class="line">Out[3]: </div><div class="line">&#123;&apos;no surfacing&apos;: &#123;0: &apos;0&apos;, 1: &#123;&apos;flippers&apos;: &#123;0: &apos;no&apos;, 1: &apos;yes&apos;&#125;&#125;&#125;&#125;</div><div class="line">In[4]: myTree = treePlotter.retrieveTree(0)</div><div class="line">In[5]: treePlotter.getNumLeafs(myTree)</div><div class="line">Out[5]: </div><div class="line">3</div><div class="line">In[6]: treePlotter.getTreeDepth(myTree)</div><div class="line">Out[6]: </div><div class="line">2</div></pre></td></tr></table></figure></p>
<p>将下面代码添加到treePlotter.py中，注意前面已经定义了createPlot()，此时我们需要更新前面的代码。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">#plotTree函数</div><div class="line">#在父子节点间填充文本信息</div><div class="line">def plotMidText(cntrPt,parentPt,txtString):</div><div class="line">    xMid = (parentPt[0] - cntrPt[0])/2.0 + cntrPt[0]</div><div class="line">    yMid = (parentPt[1] - cntrPt[1])/2.0 + cntrPt[1]</div><div class="line">    createPlot.ax1.text(xMid,yMid,txtString)</div><div class="line"></div><div class="line">#自顶向下作图,绘制图形的x轴有效范围是0.0～1.0, y轴有效范围也是0.0~1.0</div><div class="line">def plotTree(myTree,parentPt,nodeTxt):</div><div class="line">    numLeafs = getNumLeafs(myTree)    #secondDict[key]的叶节点的数量</div><div class="line">    depth = getTreeDepth(myTree)      #secondDict[key]的树深度</div><div class="line">    print &apos;numLeafs,depth:&apos;,numLeafs,&apos;,&apos;,depth</div><div class="line">    firstStr = myTree.keys()[0]</div><div class="line">    # 全局变量plotTree.totalW 存储树的宽度，全局变量PlotTree.totalD 存储树的深度，使用这两个变量计算树节点的摆放位置，这样可以将树绘制在水平方向和垂直方向的中心位置。</div><div class="line">    cntrPt = (plotTree.xOff +(1.0 + float(numLeafs))/2.0/plotTree.totalW,plotTree.yOff) #注释1</div><div class="line">    #标记子节点属性</div><div class="line">    plotMidText(cntrPt,parentPt,nodeTxt)        #这一次循环中的cntrPt(即上式)为cbtrPt,parentPt为上一轮计算出的cntrPt</div><div class="line">    plotNode(firstStr,cntrPt,parentPt,decisionNode)  #因还没画到叶节点,所以这里画的是决策节点,即此时筛选secondDict[key]还是字典</div><div class="line">    secondDict = myTree[firstStr]</div><div class="line">    #计算下一轮要用的y</div><div class="line">    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD    #下面的循环中要使用的y</div><div class="line">    for key in secondDict.keys():</div><div class="line">        if type(secondDict[key]).__name__ == &apos;dict&apos;:</div><div class="line">            plotTree(secondDict[key],cntrPt,str(key))</div><div class="line">        else:</div><div class="line">            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW</div><div class="line">            plotNode(secondDict[key],(plotTree.xOff,plotTree.yOff),cntrPt,leafNode)</div><div class="line">            plotMidText((plotTree.xOff,plotTree.yOff),cntrPt,str(key))</div><div class="line">    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD #注释2</div><div class="line"></div><div class="line">def createPlot(inTree):</div><div class="line">    fig = plt.figure(1, facecolor=&apos;white&apos;)</div><div class="line">    fig.clf()</div><div class="line">    axprops = dict(xticks=[],yticks=[])    #创建一个型为&#123;&apos;xticks&apos;: [], &apos;yticks&apos;: []&#125;的字典</div><div class="line">    createPlot.ax1 = plt.subplot(111,frameon=False,**axprops)</div><div class="line">    plotTree.totalW = float(getNumLeafs(inTree))      #树的宽度</div><div class="line">    plotTree.totalD = float(getTreeDepth(inTree))     #输的深度</div><div class="line">    plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0; #定义节点位置的初始值</div><div class="line">    plotTree(inTree,(0.5,1.0),&apos;&apos;)     #（0.5,1.0）为初始化parentPt的值，注释3</div><div class="line">    plt.show()</div></pre></td></tr></table></figure></p>
<p>在命令行输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">In[35]: reload(treePlotter)</div><div class="line">Out[35]: </div><div class="line">&lt;module &apos;treePlotter&apos; from &apos;/home/vickyleexy/PycharmProjects/Classification of contact lenses/treePlotter.py&apos;&gt;</div><div class="line">In[36]: myTree = treePlotter.retrieveTree(0)</div><div class="line">In[37]: myTree</div><div class="line">Out[37]: </div><div class="line">&#123;&apos;no surfacing&apos;: &#123;0: &apos;no&apos;, 1: &#123;&apos;flippers&apos;: &#123;0: &apos;no&apos;, 1: &apos;yes&apos;&#125;&#125;&#125;&#125;</div><div class="line">In[38]: treePlotter.createPlot(myTree)</div><div class="line">numLeafs,depth: 3 , 2</div><div class="line">numLeafs,depth: 2 , 1</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20170615230521666?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p><strong>注释：</strong><br><strong>1.</strong><code>cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)</code><br>　　在这行代码中，首先由于整个画布根据叶子节点数和深度进行平均切分，并且x轴的总长度为1,即如同下图：<br><img src="http://img.blog.csdn.net/20170615230919401?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>　　其中方形为非叶子节点的位置，@是叶子节点的位置，因此每份即上图的一个表格的长度应该为1/plotTree.totalW,但是叶子节点的位置应该为@所在位置，则在开始的时候plotTree.xOff的赋值为-0.5/plotTree.totalW,即意为开始x位置为第一个表格左边的半个表格距离位置，这样作的好处为：在以后确定@位置时候可以直接加整数倍的1/plotTree.totalW,</p>
<p> 　　plotTree.xOff即为最近绘制的一个叶子节点的x坐标，在确定当前节点位置时每次只需确定当前节点有几个叶子节点，因此其叶子节点所占的总距离就确定了即为float(numLeafs)/plotTree.totalW<em>1(因为总长度为1)，因此当前节点的位置即为其所有叶子节点所占距离的中间即一半为float(numLeafs)/2.0/plotTree.totalW</em>1，但是由于开始plotTree.xOff赋值并非从0开始，而是左移了半个表格，因此还需加上半个表格距离即为1/2/plotTree.totalW<em>1,则加起来便为(1.0 + float(numLeafs))/2.0/plotTree.totalW</em>1，因此偏移量确定，则x位置变为plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW.</p>
<p><strong>2.</strong> <code>plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD</code><br>这行代码中是需要的，当分支最后一个不是字典的时候,字典循环完需要返回上一层继续进行函数<br>例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">In[40]: myTree[&apos;no surfacing&apos;][3] = &apos;maybe&apos;</div><div class="line">In[41]: myTree</div><div class="line">Out[41]: </div><div class="line">&#123;&apos;no surfacing&apos;: &#123;0: &apos;no&apos;, 1: &#123;&apos;flippers&apos;: &#123;0: &apos;no&apos;, 1: &apos;yes&apos;&#125;&#125;, 3: &apos;maybe&apos;&#125;&#125;</div><div class="line">In[42]: treePlotter.createPlot(myTree)</div><div class="line">numLeafs,depth: 4 , 2</div><div class="line">numLeafs,depth: 2 , 1</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20170615231547780?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjE1MDM2MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>    　<br><strong>3.</strong><code>plotTree(inTree,(0.5,1.0),&#39;&#39;)</code><br>  在这行代码中，对于plotTree函数参数赋值为(0.5, 1.0)，因为开始的根节点并不用划线，因此父节点和当前节点的位置需要重合，利用2中的确定当前节点的位置便为(0.5, 1.0)</p>
<p><strong>总结：</strong>利用这样的逐渐增加x的坐标，以及逐渐降低y的坐标能能够很好的将树的叶子节点数和深度考虑进去，因此图的逻辑比例就很好的确定了，这样不用去关心输出图形的大小，一旦图形发生变化，函数会重新绘制，但是假如利用像素为单位来绘制图形，这样缩放图形就比较有难度了</p>
<h3 id="测试和存储分类器"><a href="#测试和存储分类器" class="headerlink" title="测试和存储分类器"></a>测试和存储分类器</h3><p>程序比较测试数据与决策树上的数值，递归执行该过程直到进入叶子节点，最后将测试数据定义为叶子节点所属的类型。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">#使用决策树的分类算法</div><div class="line">def classify(inputTree,featLabels,testVec):    #testVec即为需要分类的数据</div><div class="line">    firstStr = inputTree.keys()[0]</div><div class="line">    secondDict = inputTree[firstStr]</div><div class="line">    featIndex = featLabels.index(firstStr)        #将标签字符串转换为索引</div><div class="line">    print featIndex</div><div class="line">    for key in secondDict.keys():</div><div class="line">        if testVec[featIndex] == key:</div><div class="line">            if type(secondDict[key]).__name__ == &apos;dict&apos;:</div><div class="line">                classLabel = classify(secondDict[key],featLabels,testVec)</div><div class="line">            else:</div><div class="line">                classLabel = secondDict[key]</div><div class="line">    return classLabel</div></pre></td></tr></table></figure>
<p><strong>在命令行输入：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">In[19]: reload(trees)</div><div class="line">Out[19]: </div><div class="line">&lt;module &apos;trees&apos; from &apos;/home/vickyleexy/PycharmProjects/Classification of contact lenses/trees.py&apos;&gt;</div><div class="line">In[20]: myDat,labels = trees.createDataSet()</div><div class="line">In[21]: myDat</div><div class="line">Out[21]: </div><div class="line">[[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]]</div><div class="line">In[22]: labels</div><div class="line">Out[22]: </div><div class="line">[&apos;no surfacing&apos;, &apos;flippers&apos;]</div><div class="line">In[23]: myTree = trees.createTree(myDat,labels)</div><div class="line">最好的特征,最好的信息增益： 0 , 0.419973094022</div><div class="line">最好的特征,最好的信息增益： 0 , 0.918295834054</div><div class="line">In[24]: myDat</div><div class="line">Out[24]: </div><div class="line">[[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]]</div><div class="line">In[25]: labels</div><div class="line">Out[25]: </div><div class="line">[&apos;flippers&apos;]</div><div class="line">In[26]: myDat,labels = trees.createDataSet()</div><div class="line">In[27]: trees.classify(myTree,labels,[1,1])</div><div class="line">0</div><div class="line">1</div><div class="line">Out[27]: </div><div class="line">&apos;yes&apos;</div><div class="line">In[28]: trees.classify(myTree,labels,[1,0])</div><div class="line">0</div><div class="line">1</div><div class="line">Out[28]: </div><div class="line">&apos;no&apos;</div></pre></td></tr></table></figure></p>
<h3 id="决策树的存储"><a href="#决策树的存储" class="headerlink" title="决策树的存储"></a>决策树的存储</h3><p>为了节省时间，最好能够在每次执行分类时调用已经构造好的决策树，使用Python的pickle模块可以在磁盘上保存对象，并在需要的时候读取出来。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#使用pickle模块存储决策树</div><div class="line">def storeTree(inputTree,filename):</div><div class="line">    import pickle</div><div class="line">    fw = open(filename,&apos;w&apos;)</div><div class="line">    pickle.dump(inputTree,fw)</div><div class="line">    fw.close()</div><div class="line"></div><div class="line">def grabTree(filename):</div><div class="line">    import pickle</div><div class="line">    fr = open(filename)</div><div class="line">    return pickle.load(fr)</div></pre></td></tr></table></figure></p>
<p>在命令行中输入:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">In[29]: trees.storeTree(myTree,&apos;classifierStorage.txt&apos;)</div><div class="line">In[30]: trees.grabTree(&apos;classifierStorage.txt&apos;)</div><div class="line">Out[30]: </div><div class="line">&#123;&apos;no surfacing&apos;: &#123;0: &apos;no&apos;, 1: &#123;&apos;flippers&apos;: &#123;0: &apos;no&apos;, 1: &apos;yes&apos;&#125;&#125;&#125;&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2017/05/27/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        
    </entry>
    
  
  
</search>
